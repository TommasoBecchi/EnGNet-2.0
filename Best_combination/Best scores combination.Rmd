---
title: "Best combination"
author: "Tommaso Becchi"
output:
  html_document: default
  pdf_document: default
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
```

### 0. IMPORT LIBRARIES
```{r}
library("GEOquery")
library(dplyr)
library("pheatmap")
library("ggplot2")
library("limma")
library("edgeR")
library("psych")
library("igraph")
library("knitr")
library("pROC")
```

### 1. IMPORT THE DATASET
#### 1.1 Series Matrix 
```{r}
# SERIES MATRIX
info=getGEO(filename="GSE157194_series_matrix.txt")

# COUNT TABLE
gene_expression=read.delim(file="Raw_gene_counts_matrix.txt",row.names = 1)
```


#### 1.2 Extract useful information from Series Matrix 
```{r}
sampleinfo<-pData(info)
#I select only the sample measured before the start of therapy
gene_expression<-gene_expression[,1:111]
sampleinfo<-sampleinfo[1:111,]
#From sampleinfo I extract the field which refers to the AL/AN condition
sampleinfo2<-select(sampleinfo, source_name_ch1 )
rownames(sampleinfo2)<-colnames(gene_expression)
colnames(sampleinfo2)<-c("group")
#I change the varibles name to better visualize the groups
sampleinfo2$group[which(sampleinfo2$group == "m0_AL") ] <- "Lesional"
sampleinfo2$group[which(sampleinfo2$group == "m0_AN") ] <- "Non_Lesional"
head(sampleinfo2)
```

### 2. DATA PRE-PROCESSING
#### 2.1 Removing genes that are lowly expressed
```{r}
x<-DGEList(gene_expression)

#The filterByExpr function provides an automatic way to filter genes that are lowly expressed
keep.exprs <- filterByExpr(x, group=sampleinfo2$group)
x <- x[keep.exprs,, keep.lib.sizes=FALSE]
```

#### 2.2 Normalising gene expression distributions
```{r}
#Normalisation by the method of trimmed mean of M-values (TMM)
x2 <- calcNormFactors(x, method="TMM")  
```

#### 2.3 Differential gene expression analyses
```{r}
design <- model.matrix(~ 0 + sampleinfo2$group)
colnames(design) <- c("Lesional","Non_Lesional")
cont.matrix <- makeContrasts(LesVsNonLes= Lesional - Non_Lesional,levels=design)

#Voom converts raw counts to log-CPM values by automatically extracting library sizes and normalisation factors from x itself
v <- voom(x2, design, plot=FALSE)
vfit <- lmFit(v, design)
vfit <- contrasts.fit(vfit, contrasts=cont.matrix)
```

```{r}
tfit <- treat(vfit, lfc=0.5)
dt <- decideTests(tfit)
summary(dt)
results<-data.frame(dt)
results$id<-rownames(results)
DEGs<-results[results$LesVsNonLes!=0,]
```

#### 2.4 CQN of DEGs
```{r}
#Create two dataframe with raw counts, one for DEGs in lesional samples and one for DEGs in non-lesional samples
gene_final<-data.frame(x$counts)
count_AL<-gene_final[rownames(gene_final)%in% DEGs$id,sampleinfo2$group=="Lesional"]
dim(count_AL)
count_NL<-gene_final[rownames(gene_final)%in% DEGs$id,sampleinfo2$group=="Non_Lesional"]
dim(count_NL)
#Since lesional dataframe contains more samples than non.lesional one, I remove 3 columns in lesional dataframe
count_AL<-count_AL[,1:54]
```


```{r}
### This function takes in input an expression matrix with raw data and it calculates the matrix with CQN data

cqn_data<-function(hsmart,raw_count){
  library("cqn")
  biomart2<- getBM(attributes=c('ensembl_gene_id','start_position','end_position', 'percentage_gene_gc_content'), filters = 'ensembl_gene_id', values =rownames(raw_count), mart = hsmart)   
  biomart2$length<-biomart2$end_position-biomart2$start_position
  gene_length_gc<-biomart2[,c(1,4,5)]
  both <-rownames (raw_count)%in% gene_length_gc$ensembl_gene_id
  raw_count<-raw_count[both==TRUE,]
  cqn.subset<-cqn(raw_count,lengths=gene_length_gc$length,x=gene_length_gc$percentage_gene_gc_content)
  normalized_data<-data.frame(cqn.subset$y+cqn.subset$offset)
}

```

```{r}
library("biomaRt")
hsmart <- useMart(dataset = "hsapiens_gene_ensembl", biomart = "ensembl")
normalized_count_AL<-cqn_data(hsmart,count_AL)
normalized_count_NL<-cqn_data(hsmart,count_NL)
```



### 3 Correlation matrices
I chose Biweight Midcorrelation as second non-linear score. It is median-based, rather than mean-based, thus is less sensitive to outliers, and can be a robust alternative to other similarity metrics, such as Pearson correlation or mutual information.

This measure was used for a gene co-expression study in "Zheng, Chun-Hou, et al. "Gene differential coexpression analysis based on biweight correlation and maximum clique." BMC bioinformatics. Vol. 15. No. 15. BioMed Central, 2014." 
The results explain that Biweight Midcorrelation is more robust for outliers than other methods.

```{r}
### This function takes in input a dataframe with NxN gene-gene interactions and it returns a daframe with a single row for each pair of gene anf the value of their correlation.

flattenCorrMatrix <- function(cormat, pmat) {
  ut <- upper.tri(cormat)
  data.frame(
    row = rownames(cormat)[row(cormat)[ut]],
    column = rownames(cormat)[col(cormat)[ut]],
    cor  =(cormat)[ut],
    p = pmat[ut]
  )
}
```


```{r}
### This function takes in input a dataframe with NxN gene-gene interactions. It first calculates the value of the correlation for each pair of genes for the 4 selected measures. Then, it uses "flattenCorrMatrix" function to obtain the dataframes wit a single row for each relationship and in the end, it combines all the scores in a single dataframe with 6 columns: gene1-gene2-kendall-pearson-NMI-bicor

scores<-function(tab){
  #### Kendall
  kendall<-corr.test(t(tab),method="kendall",adjust="BH",ci=FALSE)
  kendall<-flattenCorrMatrix(kendall$r,kendall$p)
  
  #### Spearman
  spearman<-corr.test(t(tab),method="spearman",adjust="BH",ci=FALSE)
  spearman<-flattenCorrMatrix(spearman$r,spearman$p)
  
  #### NMI
  library("SNFtool")
  g1<-c()
  g2<-c()
  val<-c()

  for (i in 1:(dim(tab)[1]-1)){
    p<-i+1
    for(j in p:dim(tab)[1]){
      g1<-c(g1,rownames(tab)[i])
      g2<-c(g2,rownames(tab)[j])
      val<-c(val,calNMI(as.numeric(tab[i,]),as.numeric(tab[j,])))
    }
  }

  nmi<-data.frame(g1,g2,val)
  
  #### Biweight Midcorrelation
  library("WGCNA")
  bicor<-bicorAndPvalue(t(tab), y=NULL)
  bicor<-flattenCorrMatrix(bicor$bicor,bicor$p)
  
  bicor<-bicor[order(bicor$row),]

  final<-data.frame("gene1"=kendall$row,"gene2"=kendall$column,"kendall"=kendall$cor,"spearman"=spearman$cor)
  final<-final[order(final$gene1),]
  final$nmi<-nmi$val
  final$bicor<-bicor$cor

  final
}

```

### 4 Best thresholds

```{r}
### This function takes in input a dataframe with a row for each gene-gene correlation and one of the 4 columns between kendall, pearson, nmi and bicor. It returns the threshold that allows to obtain the network that better fits with a power-low distribution.

best_thresholds<-function(interactions,column,start_v,end_v){
  thr<-c()
  score<-c()
  for (i in seq (start_v,end_v,0.01)){
  data<-interactions[abs(interactions[,column])>=i,c(1,2,column)]
  g<-graph_from_data_frame(data,directed=F)
  dist<-degree.distribution(g)
  power_law<-fit_power_law(dist)
  thr<-c(thr,i)
  #K.stat describes how better the distribution fits a power-law. Smaller scores denote better fit.
  score<-c(score,power_law$KS.stat)
  }
  result_L=data.frame(threshold=thr,score=score)
  best<-min(score)
  result_L[result_L$score==best,]$threshold
}

```


```{r}
### This function takes in input a dataframe with a single row for each gene-gene relationship. It first uses "best_thresholds" function to calculate the 4 best thresholds. Then it creates a new dataframe with a row for each gene-gene relationship with 6 column gene1-gene2-kendall-spearma-NMI-bicor. The last 4 column contains TRUE/FALSE if the score is above or not the best threshold.

TrueAndFalse<-function(tab){
  best_L<-c()
  ### Kendall
  best_L<-c(best_L,best_thresholds(tab,3,0.1,0.75))
  ### Spearman
  best_L<-c(best_L,best_thresholds(tab,4,0.1,0.9))
  ### NMI
  best_L<-c(best_L,best_thresholds(tab,5,0.4,0.95))
  ### Biweight Midcorrelation
  best_L<-c(best_L,best_thresholds(tab,6,0.1,0.9))
  
  best_thr<-data.frame(t(best_L))
  
  trueandfalse<-tab[,c(1,2)]
  for (i in 1:4){
    over<-c()
    for (j in 1:dim(trueandfalse)[1]){
      if (abs(tab[j,i+2])>=best_thr[1,i]){over<-c(over,TRUE)}
      else {over<-c(over,FALSE)}
    }
    trueandfalse[,i+2]<-over
  }

  colnames(trueandfalse)<-c("gene1","gene2","kendall","spearman","NMI","Bicor")
  trueandfalse
}
```


### 5. Best combination

```{r}
### This daframe shows all the possible combinations with at lest one TRUE

all_comb<-data.frame(
  (c(T,T,T,T)),(c(T,T,T,F)),(c(T,T,F,T)),
  (c(T,F,T,T)),(c(F,T,T,T)),(c(T,T,F,F)),
  (c(T,F,T,F)),(c(T,F,F,T)),(c(F,T,T,F)),
  (c(F,T,F,T)),(c(F,F,T,T)),(c(T,F,F,F)),
  (c(F,T,F,F)),(c(F,F,T,F)),(c(F,F,F,T))
)

all_comb<-data.frame(t(all_comb))
rownames(all_comb)<-c("K+S+N+B","K+S+N","K+S+B","K+N+B","S+N+B","K+S","K+N","K+B","S+N","S+B","N+B","K","S","N","B")
colnames(all_comb)<-c("kendall","spearman","NMI","Bicor")
all_comb
```

```{r}
### This function takes in input the dataframe created by "TrueAndFalse" function. It creates 15 new dataframes with the gene-gene relationships that belong to a specific combination. It returns a single list that contains 15 dataframes.

all_combinations<-function(trueandfalse,final){
  g1<-final[trueandfalse$kendall==T & trueandfalse$spearman==T & trueandfalse$NMI==T & trueandfalse$Bicor==T,]
  g2<-final[trueandfalse$kendall==T & trueandfalse$spearman==T & trueandfalse$NMI==T & trueandfalse$Bicor==F,]
  g3<-final[trueandfalse$kendall==T & trueandfalse$spearman==T & trueandfalse$NMI==F & trueandfalse$Bicor==T,]
  g4<-final[trueandfalse$kendall==T & trueandfalse$spearman==F & trueandfalse$NMI==T & trueandfalse$Bicor==T,]
  g5<-final[trueandfalse$kendall==F & trueandfalse$spearman==T & trueandfalse$NMI==T & trueandfalse$Bicor==T,]
  g6<-final[trueandfalse$kendall==T & trueandfalse$spearman==T & trueandfalse$NMI==F & trueandfalse$Bicor==F,]
  g7<-final[trueandfalse$kendall==T & trueandfalse$spearman==F & trueandfalse$NMI==T & trueandfalse$Bicor==F,]
  g8<-final[trueandfalse$kendall==T & trueandfalse$spearman==F & trueandfalse$NMI==F & trueandfalse$Bicor==T,]
  g9<-final[trueandfalse$kendall==F & trueandfalse$spearman==T & trueandfalse$NMI==T & trueandfalse$Bicor==F,]
  g10<-final[trueandfalse$kendall==F & trueandfalse$spearman==T & trueandfalse$NMI==F & trueandfalse$Bicor==T,]
  g11<-final[trueandfalse$kendall==F & trueandfalse$spearman==F & trueandfalse$NMI==T & trueandfalse$Bicor==T,]
  g12<-final[trueandfalse$kendall==T & trueandfalse$spearman==F & trueandfalse$NMI==F & trueandfalse$Bicor==F,]
  g13<-final[trueandfalse$kendall==F & trueandfalse$spearman==T & trueandfalse$NMI==F & trueandfalse$Bicor==F,]
  g14<-final[trueandfalse$kendall==F & trueandfalse$spearman==F & trueandfalse$NMI==T & trueandfalse$Bicor==F,]
  g15<-final[trueandfalse$kendall==F & trueandfalse$spearman==F & trueandfalse$NMI==F & trueandfalse$Bicor==T,]
  total<-list(g1,g2,g3,g4,g5,g6,g7,g8,g9,g10,g11,g12,g13,g14,g15)
}
```


```{r}
### This function takes in input a dataframe and a specific TRUE/FALSE combination. It calculates the average value of the TRUE scores for each relationship in the dataframe.

meanTrue<-function (g,v){
  newc<-c()
  for (i in 1:dim(g)[1]){
    ll<-c()
    for (j in (1:4)){
      if (v[j]){ll<-c(ll,abs(g[i,j+2]))}
    }
  newc<-c(newc,mean(ll))
  }
  newc
}
```

```{r}
### This function takes in input the list with 15 datframes created by "all_combinations" function and the dataframe with the 15 combinations (all_comb). It uses "meanTrue" function to add a new "mean" column with the avreage value of the TRUE interactions only in the dataframe with more than 30 data.

mean_column<-function(total_g,all_comb){
  for (i in 1:15){
    if (dim(total_g[[i]])[1]>30){
      total_g[[i]]$mean<-meanTrue(total_g[[i]],as.character(all_comb[i,]))
    }
  }
  total_g
}
```


### 6. Validation with STRING
```{r}
string<-read.table("string_homosapiens.txt",sep=" ",header=T)
string<-string[string$coexpression>0,c(1,2,6)]
library("STRINGdb")
# Download interactions for human networks (9606).
string_db <- STRINGdb$new( version="11", species=9606, score_threshold=0, input_directory="")

```


```{r}
### This function takes in input a datframe in the format gene1-gene2-kendall-pearson-nmi-bicor-avreage. It selected only gene1-gene2-average columns and convert the gene identifiers in STRING ids. Then, it compares the dataframe with STRING and it adds a colmun with TRUE/FALSE it the relationship is present or not in STRING

prediction<-function(g){
  g<-g[,c(1,2,7)]
  network_mapped <- string_db$map(g, c("gene1"), removeUnmappedRows = TRUE)
  colnames(network_mapped)<-c("gene1","gene2","mean","String1")
  network_mapped <- string_db$map(network_mapped, "gene2", removeUnmappedRows = TRUE)
  colnames(network_mapped)<-c("gene1","gene2","mean","String1","String2")

  network_mapped$check <- ifelse(is.na(match(paste0(network_mapped$String1, network_mapped$String2),paste0(string$protein1, string$protein2))), FALSE, TRUE)
  network_mapped
}
```

```{r}
### This function takes in input the list with 15 dataframes. First, it uses "prediction" function to compare the dataframe with more than 3o data to STRING. Then, it plots ROC curve and it calculates the auROC.

plot_roc<-function(total_g){
  col <-rainbow(15)
  first=T
  leg<-c()
  col_legend<-c()
  auroc_val<-c()
  for (i in 1:15){
    if (dim(total_g[[i]])[1]>30){
      r<-prediction(total_g[[i]])
      auroc_val<-c(auroc_val,auROC(r$check, stat=NULL))
      if(first){
        plot.roc(r$check,r$mean,col=col[i])
        first=F
      }
      else{lines.roc(r$check,r$mean,col=col[i])}
      leg<-c(leg,row.names(all_comb)[i])
      col_legend<-c(col_legend,col[i])
    }
  }
  legend("bottomright", legend=leg, col=col_legend, lwd=2)
  data.frame("pred"=leg, "auroc"=auroc_val)
}
```


```{r}
### This function combines all the previuos functions and it allows to use as input only the normalized dataframe and the dataframe with all the combinations.

total<-function(normalized_count,all_comb){
  data_scores<-scores(normalized_count)
  OverThr<-TrueAndFalse(data_scores)
  total_g<-all_combinations(OverThr,data_scores)
  total_g<-mean_column(total_g,all_comb)
  data_auroc<-plot_roc(total_g)
}

```

```{r message=FALSE, warning=FALSE}
#### LESIONAL

auroc_lesional<-total(normalized_count_AL,all_comb)
auroc_lesional

```

```{r message=FALSE, warning=FALSE}
### NON-LESIONAL
auroc_non_lesional<-total(normalized_count_NL,all_comb)
auroc_non_lesional
```



